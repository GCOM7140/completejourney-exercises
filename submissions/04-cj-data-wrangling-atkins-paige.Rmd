---
title: "Data Wrangling Exercises"
output: github_document
author: Paige Atkins
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

The following four exercises are based on concepts covered in 
[Chapter 12][G&W 2017, 12] and [Chapter 13][G&W 2017, 13] of 
[R for Data Science][G&W 2017]. Use the `coupon`, `coupon_redempt`, 
`campaign_table`, `transaction_data`, and `product` datasets that come with the 
`completejourney` package to work on them, and start by loading the `tidyverse` 
and `completejourney` packages.

```{r, echo = TRUE, eval = TRUE, message = FALSE}
library(tidyverse)
library(completejourney)
```

---

## Exercise 1
#What percent of households that received the retailer's weekly mailer redeemed 
at least one coupon?

hh_coupon_counts <- coupon_redempt %>% count(household_key)
hh_campaign_participants <- campaign_table %>% distinct(household_key)
hh_redemption_check <- left_join(hh_campaign_participants, 
                                 hh_coupon_counts, by='household_key')
mean(!is.na(hh_redemption_check$n))

#27.39 percent of households received the mailer and redeemed at least one coupon
---

## Exercise 2
#How many households did not redeem a coupon?   

hh_coupon_counts <- coupon_redempt %>% count(household_key)
hh_campaign_participants <- campaign_table %>% distinct(household_key)

anti_join(hh_campaign_participants, 
          hh_coupon_counts, by='household_key') %>% nrow()

#1150 Households didnt redeem a coupon

---

## Exercise 3
What percent of coupons promoted in the retailer's weekly mailer got redeemed at
least once?

hh_coupon_counts <- coupon_redempt %>% count(household_key)
hh_campaign_participants <- campaign_table %>% distinct(household_key)
hh_redemption_check <- left_join(hh_campaign_participants, 
                                 hh_coupon_counts, by='household_key')
mean(!is.na(hh_redemption_check$n))

#27.39 percent of households received the mailer and redeemed at least one coupon (Same as #1?)



---

## Exercise 4
Using the `transaction_data` and `product` datasets, determine which product
category (i.e., `sub_commodity_desc`) grew the most in terms of revenue for the
retailer in the second half of the study period (i.e., between `week_no == 52` 
and `week_no == 102`). Only consider product categories that had over $100 in
revenue in week 52, and calculate revenue growth as a percentage of category
revenue in week 52.

#Here are some suggested steps: 
 1. Join the `transaction_data` and `product` datasets.
 2. Group the data by `sub_commodity_desc` and `week_no`.
 3. Calculate `sales_value` at the category level.
 4. Filter the data to only include category revenues in weeks 52 and 102.
 5. Create a new variable called `revenue_growth`, making use of the `lag()`
 function. Recognize that you only want to consider categories that had category
 revenues of at least $100 in week 52.
 6. Arrange the data in descending order according to `revenue_growth`.


transaction_data %>%
  left_join(product, by='product_id') %>%
  group_by(commodity_desc, week_no) %>%
  summarize(total_sales_value = sum(sales_value, na.rm=TRUE)) %>%
  arrange(commodity_desc, week_no) %>%
  group_by(commodity_desc) %>%
  filter(row_number() == 1 | row_number() == n()) %>%
  select(-week_no) %>%
  mutate(week_indicator = ifelse(row_number() == 1, 'first', 'last')) %>%
  spread(key = week_indicator, value = total_sales_value) %>%
  mutate(growth = (last-first) / first) %>%
  filter(first >= 100) %>%
  arrange(desc(growth))
  
#Fluid milk product had the most growth